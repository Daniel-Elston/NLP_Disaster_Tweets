{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('axes', grid=True)\n",
    "\n",
    "import contractions\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'C:/Users/delst/OneDrive/Desktop/Code/Workspace/NLP_Disaster_Tweets'\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from A_Main.Configurations.setup_env import setup_environment\n",
    "config = setup_environment(root_dir)\n",
    "\n",
    "# File Paths\n",
    "sdo_pkl = config.sdo_pkl\n",
    "sdo_parq = config.sdo_parq\n",
    "\n",
    "# Class Imports\n",
    "from Modularization.corpus_creation import CorpusBowCreator, load_corpus_bow\n",
    "\n",
    "fig_size = config.fig_size_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C1_Initial_Processing/train.parquet'\n",
    "path_to_parq_store = os.path.join(sdo_parq, filename)\n",
    "\n",
    "df_train = pd.read_parquet(path_to_parq_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C1_Initial_Processing/test.parquet'\n",
    "path_to_parq_store = os.path.join(sdo_parq, filename)\n",
    "\n",
    "df_test = pd.read_parquet(path_to_parq_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc theyve built so much hype ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword                                               text  target\n",
       "25  ablaze        we always try to bring the heavy #metal #rt       0\n",
       "26  ablaze  #africanbaze breaking newsnigeria flag set abl...       1\n",
       "27  ablaze                 crying out for more! set me ablaze       0\n",
       "28  ablaze  on plus side look at the sky last night it was...       0\n",
       "29  ablaze  @phdsquares #mufc theyve built so much hype ar...       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>birmingham wholesale market is ablaze bbc news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#previouslyondoyintv toke makinwaûªs marriage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>check these out    #nsfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>psa iûªm splitting my personalities?? techies ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword                                               text\n",
       "15  ablaze  birmingham wholesale market is ablaze bbc news...\n",
       "16  ablaze  @sunkxssedharry will you wear shorts for race ...\n",
       "17  ablaze  #previouslyondoyintv toke makinwaûªs marriage ...\n",
       "18  ablaze                           check these out    #nsfw\n",
       "19  ablaze  psa iûªm splitting my personalities?? techies ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(contractions.fix)\n",
    "df_test['text'] = df_test['text'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0\n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1\n",
       "27     ablaze                 crying out for more! set me ablaze       0\n",
       "28     ablaze  on plus side look at the sky last night it was...       0\n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0\n",
       "...       ...                                                ...     ...\n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0\n",
       "6063  wrecked  three days off from work and they have pretty ...       0\n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0\n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0\n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0\n",
       "\n",
       "[6042 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "df['tokens'] = df['text'].apply(tokenizer.tokenize)\n",
    "df_test['tokens'] = df_test['text'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[we, always, try, to, bring, the, heavy, #meta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, out, for, more, !, set, me, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[on, plus, side, look, at, the, sky, last, nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, they, have, built, so, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, and, i, wrecked, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[three, days, off, from, work, and, they, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@engineshed, great, atmosphere, at, the, brit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cramer, igers, 3, words, that, wrecked, disne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target  \\\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27     ablaze                 crying out for more! set me ablaze       0   \n",
       "28     ablaze  on plus side look at the sky last night it was...       0   \n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "...       ...                                                ...     ...   \n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0   \n",
       "6063  wrecked  three days off from work and they have pretty ...       0   \n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0   \n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0   \n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0   \n",
       "\n",
       "                                                 tokens  \n",
       "25    [we, always, try, to, bring, the, heavy, #meta...  \n",
       "26    [#africanbaze, breaking, newsnigeria, flag, se...  \n",
       "27         [crying, out, for, more, !, set, me, ablaze]  \n",
       "28    [on, plus, side, look, at, the, sky, last, nig...  \n",
       "29    [@phdsquares, #mufc, they, have, built, so, mu...  \n",
       "...                                                 ...  \n",
       "6062  [@jt_ruff23, @cameronhacker, and, i, wrecked, ...  \n",
       "6063  [three, days, off, from, work, and, they, have...  \n",
       "6064  [#fx, #forex, #trading, cramer, igers, 3, word...  \n",
       "6065  [@engineshed, great, atmosphere, at, the, brit...  \n",
       "6066  [cramer, igers, 3, words, that, wrecked, disne...  \n",
       "\n",
       "[6042 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/delst/OneDrive/Desktop/Code/Workspace/NLP_Disaster_Tweets\\Modularization\\corpus_creation.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[self.token_col] = self.df[self.token_col].apply(self.remove_stop_words)\n"
     ]
    }
   ],
   "source": [
    "processor_1 = CorpusBowCreator.create_corpus(df, 1, 'tokens')\n",
    "processor_0 = CorpusBowCreator.create_corpus(df, 0, 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#africanbaze',\n",
       " 'breaking',\n",
       " 'newsnigeria',\n",
       " 'flag',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'aba',\n",
       " 'barbados',\n",
       " '#bridgetown',\n",
       " 'jamaica',\n",
       " 'ûò',\n",
       " 'two',\n",
       " 'cars',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'santa',\n",
       " 'cruz',\n",
       " 'ûó',\n",
       " 'head',\n",
       " 'st',\n",
       " 'elizabeth',\n",
       " 'police',\n",
       " 'superintende',\n",
       " 'west',\n",
       " 'burned',\n",
       " 'thousands',\n",
       " 'wildfires',\n",
       " 'ablaze',\n",
       " 'california',\n",
       " 'alone',\n",
       " 'man',\n",
       " 'wife',\n",
       " 'get',\n",
       " 'six',\n",
       " 'years',\n",
       " 'jail',\n",
       " 'setting',\n",
       " 'ablaze',\n",
       " 'niece',\n",
       " 'police',\n",
       " 'arsonist',\n",
       " 'deliberately',\n",
       " 'set',\n",
       " 'black',\n",
       " 'church',\n",
       " 'north',\n",
       " 'carolinaåêablaze',\n",
       " '#kurds',\n",
       " 'trampling',\n",
       " 'turkmen',\n",
       " 'flag',\n",
       " 'later',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'others',\n",
       " 'vandalized',\n",
       " 'offices',\n",
       " 'turkmen',\n",
       " 'front',\n",
       " '#diyala',\n",
       " 'west',\n",
       " 'burned',\n",
       " 'thousands',\n",
       " 'wildfires',\n",
       " 'ablaze',\n",
       " '#california',\n",
       " 'alone',\n",
       " '#climate',\n",
       " '#energy',\n",
       " '@navista7',\n",
       " 'steve',\n",
       " 'fires',\n",
       " 'something',\n",
       " 'else',\n",
       " '!',\n",
       " 'california',\n",
       " 'tinderbox',\n",
       " 'clown',\n",
       " 'setting',\n",
       " 'hood',\n",
       " 'ablaze',\n",
       " '@news24680',\n",
       " 'accident',\n",
       " 'i24',\n",
       " 'w',\n",
       " '#nashvilletraffic',\n",
       " 'traffic',\n",
       " 'moving',\n",
       " '8m',\n",
       " 'slower',\n",
       " 'usual',\n",
       " 'httpstco',\n",
       " '0ghk693egj',\n",
       " 'reported',\n",
       " 'motor',\n",
       " 'vehicle',\n",
       " 'accident',\n",
       " 'curry',\n",
       " 'herman',\n",
       " 'rd',\n",
       " 'near',\n",
       " 'stephenson',\n",
       " 'involving',\n",
       " 'overturned',\n",
       " 'vehicle',\n",
       " 'please',\n",
       " 'use',\n",
       " 'i77',\n",
       " 'mile',\n",
       " 'marker',\n",
       " '31',\n",
       " 'south',\n",
       " 'mooresville',\n",
       " 'iredell',\n",
       " 'vehicle',\n",
       " 'accident',\n",
       " 'ramp',\n",
       " 'closed',\n",
       " '86',\n",
       " '118',\n",
       " 'pm',\n",
       " 'traffic',\n",
       " 'accident',\n",
       " 'n',\n",
       " 'cabrillo',\n",
       " 'hwymagellan',\n",
       " 'av',\n",
       " 'mir',\n",
       " '080615 1103',\n",
       " '58',\n",
       " 'i77',\n",
       " 'mile',\n",
       " 'marker',\n",
       " '31',\n",
       " '40',\n",
       " 'south',\n",
       " 'mooresville',\n",
       " 'iredell',\n",
       " 'vehicle',\n",
       " 'accident',\n",
       " 'congestion',\n",
       " '86',\n",
       " '118',\n",
       " 'pm',\n",
       " 'horrible',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'past',\n",
       " 'sunday',\n",
       " 'finally',\n",
       " 'able',\n",
       " 'get',\n",
       " 'around',\n",
       " 'thank',\n",
       " 'god',\n",
       " '?',\n",
       " '?',\n",
       " '#truckcrash',\n",
       " 'overturns',\n",
       " '#fortworth',\n",
       " 'interstate',\n",
       " 'click',\n",
       " 'crashgt',\n",
       " 'carolina',\n",
       " 'accident',\n",
       " 'motorcyclist',\n",
       " 'dies',\n",
       " 'i540',\n",
       " 'crash',\n",
       " 'car',\n",
       " 'crossed',\n",
       " 'median',\n",
       " 'motorcycle',\n",
       " 'rider',\n",
       " 'traveling',\n",
       " 'fyi',\n",
       " 'cadfyi',\n",
       " 'accident',\n",
       " 'property',\n",
       " 'damagenhs',\n",
       " '999',\n",
       " 'piner',\n",
       " 'rdhorndale',\n",
       " 'dr',\n",
       " 'accident',\n",
       " 'property',\n",
       " 'damage',\n",
       " 'piner',\n",
       " 'rdhorndale',\n",
       " 'dr',\n",
       " '862015',\n",
       " '@209',\n",
       " 'pm',\n",
       " 'traffic',\n",
       " 'accident',\n",
       " 'injury',\n",
       " '2781',\n",
       " 'willis',\n",
       " 'foreman',\n",
       " 'rd',\n",
       " 'suffield',\n",
       " 'alberta',\n",
       " 'accident',\n",
       " 'httpstcobptmlf',\n",
       " '4p10',\n",
       " '#breaking',\n",
       " 'deadly',\n",
       " 'motorcycle',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'happened',\n",
       " '#hagerstown',\n",
       " 'today',\n",
       " 'ill',\n",
       " 'details',\n",
       " '5',\n",
       " '@your4state',\n",
       " '#whag',\n",
       " 'car',\n",
       " 'even',\n",
       " 'week',\n",
       " 'got',\n",
       " 'fucking',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'mfs',\n",
       " 'cannot',\n",
       " 'fucking',\n",
       " 'drive',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'experts',\n",
       " '#news',\n",
       " 'strict',\n",
       " 'liability',\n",
       " 'context',\n",
       " 'airplane',\n",
       " 'accident',\n",
       " 'pilot',\n",
       " 'error',\n",
       " 'common',\n",
       " 'component',\n",
       " 'aviation',\n",
       " 'cr',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'experts',\n",
       " 'wedn',\n",
       " '@alexalltimelow',\n",
       " 'awwww',\n",
       " 'airplane',\n",
       " 'accident',\n",
       " 'going',\n",
       " 'die',\n",
       " 'cuties',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'good',\n",
       " 'job',\n",
       " '!',\n",
       " 'family',\n",
       " 'members',\n",
       " 'osama',\n",
       " 'bin',\n",
       " 'laden',\n",
       " 'died',\n",
       " 'airplane',\n",
       " 'accident',\n",
       " 'ironic',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'mhmmm',\n",
       " 'gov',\n",
       " 'shit',\n",
       " 'suspect',\n",
       " 'man',\n",
       " 'goes',\n",
       " 'airplane',\n",
       " 'engine',\n",
       " 'accident',\n",
       " 'via',\n",
       " '@youtube',\n",
       " 'horrible',\n",
       " 'accident',\n",
       " 'man',\n",
       " 'died',\n",
       " 'wings',\n",
       " 'airplane',\n",
       " '2907201',\n",
       " '5',\n",
       " 'cessna',\n",
       " 'airplane',\n",
       " 'accident',\n",
       " 'ocampo',\n",
       " 'coahuila',\n",
       " 'mexico',\n",
       " 'july',\n",
       " '29',\n",
       " '2015',\n",
       " 'killed',\n",
       " 'four',\n",
       " 'men',\n",
       " 'including',\n",
       " 'state',\n",
       " 'coahuila',\n",
       " 'government',\n",
       " 'official',\n",
       " '#horrible',\n",
       " '#accident',\n",
       " 'man',\n",
       " 'died',\n",
       " 'wings',\n",
       " 'airplane',\n",
       " '2907201',\n",
       " '5',\n",
       " '#watchthevideo',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'experts',\n",
       " 'wednesdayû',\n",
       " '_',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'experts',\n",
       " 'wednesday',\n",
       " 'began',\n",
       " 'examining',\n",
       " '#kca',\n",
       " '#votejkt48id',\n",
       " 'mbataweel',\n",
       " '#rip',\n",
       " '#binladen',\n",
       " 'family',\n",
       " 'members',\n",
       " 'killed',\n",
       " 'airplanes',\n",
       " 'accident',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'experts',\n",
       " '#mlb',\n",
       " 'unbelievably',\n",
       " 'insane',\n",
       " '#man',\n",
       " '#airport',\n",
       " '#airplane',\n",
       " '#aircraft',\n",
       " '#aeroplane',\n",
       " '#runway',\n",
       " '#accident',\n",
       " '#freakyû_',\n",
       " 'httpstcocezhq',\n",
       " '7czll',\n",
       " 'horrible',\n",
       " 'accident',\n",
       " 'man',\n",
       " 'died',\n",
       " 'wings',\n",
       " 'airplaneåê',\n",
       " '2907201',\n",
       " '5',\n",
       " 'horrible',\n",
       " 'accident',\n",
       " 'man',\n",
       " 'died',\n",
       " 'wings',\n",
       " 'airplane',\n",
       " '2907201',\n",
       " '5',\n",
       " 'usama',\n",
       " 'bin',\n",
       " 'ladins',\n",
       " 'family',\n",
       " 'dead',\n",
       " 'airplane',\n",
       " 'crash',\n",
       " 'naturally',\n",
       " 'accident',\n",
       " 'dtn',\n",
       " 'brazil',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'exp',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'experts',\n",
       " 'wedn',\n",
       " 'horrible',\n",
       " 'accident',\n",
       " 'man',\n",
       " 'died',\n",
       " 'wings',\n",
       " 'ûïairplaneû',\n",
       " '2907201',\n",
       " '5',\n",
       " 'wtf',\n",
       " 'canûªt',\n",
       " 'believe',\n",
       " 'eyes',\n",
       " 'ûò',\n",
       " 'nicole',\n",
       " 'fletcher',\n",
       " 'one',\n",
       " 'victim',\n",
       " 'crashed',\n",
       " 'airplane',\n",
       " 'times',\n",
       " 'ago',\n",
       " 'accident',\n",
       " 'left',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'trauma',\n",
       " 'although',\n",
       " 'omg',\n",
       " 'horrible',\n",
       " 'accident',\n",
       " 'man',\n",
       " 'died',\n",
       " 'wings',\n",
       " 'airplane',\n",
       " '#omg',\n",
       " '!',\n",
       " 'believe',\n",
       " '#rip',\n",
       " 'bro',\n",
       " '#airplane',\n",
       " '#accident',\n",
       " '#jetengine',\n",
       " '#turbojet',\n",
       " '#boing',\n",
       " '#g90',\n",
       " 'experts',\n",
       " 'france',\n",
       " 'begin',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'debris',\n",
       " 'found',\n",
       " 'reunion',\n",
       " 'island',\n",
       " 'french',\n",
       " 'air',\n",
       " 'accident',\n",
       " 'experts',\n",
       " 'wednesday',\n",
       " 'began',\n",
       " 'examining',\n",
       " 'airplane',\n",
       " 'accident',\n",
       " 'could',\n",
       " 'drone',\n",
       " 'airplane',\n",
       " 'accident',\n",
       " '?',\n",
       " 'pilots',\n",
       " 'worried',\n",
       " 'use',\n",
       " 'drones',\n",
       " 'esp',\n",
       " 'close',\n",
       " 'vicinity',\n",
       " 'airports',\n",
       " '#',\n",
       " 'early',\n",
       " 'wake',\n",
       " 'call',\n",
       " 'sister',\n",
       " 'begging',\n",
       " 'come',\n",
       " 'amp',\n",
       " 'ride',\n",
       " 'wher',\n",
       " 'ambulance',\n",
       " 'hospital',\n",
       " '#rodkiai',\n",
       " 'two',\n",
       " 'air',\n",
       " 'ambulances',\n",
       " 'scene',\n",
       " 'serious',\n",
       " 'crash',\n",
       " 'two',\n",
       " 'cars',\n",
       " 'lorry',\n",
       " '#emsneû_',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'reuters',\n",
       " '#yugvani',\n",
       " '@20skyhawkmm20',\n",
       " '@traplord_29',\n",
       " '@fredosantana300',\n",
       " '@lilreese300',\n",
       " 'hella',\n",
       " 'crazy',\n",
       " '3',\n",
       " 'fights',\n",
       " 'ambulance',\n",
       " 'couple',\n",
       " 'mosh',\n",
       " 'pits',\n",
       " '?',\n",
       " '?',\n",
       " '#news',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " '#til_now',\n",
       " '#dna',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'pakistan',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'kills',\n",
       " 'nine',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'know',\n",
       " 'way',\n",
       " 'ambulance',\n",
       " 'coming',\n",
       " 'ltlt',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " '#worldnews',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " '#worldnews',\n",
       " 'twelve',\n",
       " 'feared',\n",
       " 'killed',\n",
       " 'pakistani',\n",
       " 'air',\n",
       " 'ambulance',\n",
       " 'helicopter',\n",
       " 'crash',\n",
       " 'annihilated',\n",
       " 'abs',\n",
       " '?',\n",
       " '?',\n",
       " 'cop',\n",
       " 'pulls',\n",
       " 'drunk',\n",
       " 'driver',\n",
       " 'safety',\n",
       " 'seconds',\n",
       " 'car',\n",
       " 'hit',\n",
       " 'train',\n",
       " 'via',\n",
       " '@viralspell',\n",
       " 'cop',\n",
       " 'pulls',\n",
       " 'drunk',\n",
       " 'driver',\n",
       " 'safety',\n",
       " 'seconds',\n",
       " 'car',\n",
       " 'hit',\n",
       " 'train',\n",
       " 'via',\n",
       " '@viralspell',\n",
       " '@violentfeminazi',\n",
       " 'guess',\n",
       " 'ok',\n",
       " 'armenians',\n",
       " 'since',\n",
       " 'spent',\n",
       " 'history',\n",
       " 'getting',\n",
       " 'annihilated',\n",
       " '70',\n",
       " 'years',\n",
       " 'since',\n",
       " 'annihilated',\n",
       " '100000',\n",
       " 'people',\n",
       " 'instantly',\n",
       " 'became',\n",
       " 'aware',\n",
       " 'ability',\n",
       " 'annihilate',\n",
       " 'whole',\n",
       " 'humanity',\n",
       " '1960s',\n",
       " 'oryx',\n",
       " 'symbol',\n",
       " 'arabian',\n",
       " 'peninsula',\n",
       " 'annihilated',\n",
       " 'hunters',\n",
       " 'ready',\n",
       " 'get',\n",
       " 'annihilated',\n",
       " 'bucs',\n",
       " 'game',\n",
       " '@tomcatarts',\n",
       " 'thus',\n",
       " 'explaining',\n",
       " 'annihilated',\n",
       " 'case',\n",
       " 'survivor',\n",
       " 'evolved',\n",
       " 'became',\n",
       " 'godlike',\n",
       " 'cop',\n",
       " 'pulls',\n",
       " 'drunk',\n",
       " 'driver',\n",
       " 'safety',\n",
       " 'seconds',\n",
       " 'car',\n",
       " 'hit',\n",
       " 'train',\n",
       " 'via',\n",
       " '@viralspell',\n",
       " '@rvfriedmann',\n",
       " 'hell',\n",
       " 'fraction',\n",
       " 'belief',\n",
       " 'total',\n",
       " 'annihilation',\n",
       " 'destruction',\n",
       " 'usa',\n",
       " '@lodisilverado',\n",
       " '@ritzy_jewels',\n",
       " 'starmade',\n",
       " 'stardate',\n",
       " '3',\n",
       " 'planetary',\n",
       " 'annihilation',\n",
       " 'via',\n",
       " '@youtube',\n",
       " 'us',\n",
       " 'national',\n",
       " 'park',\n",
       " 'services',\n",
       " 'tonto',\n",
       " 'national',\n",
       " 'forest',\n",
       " 'stop',\n",
       " 'annihilation',\n",
       " 'salt',\n",
       " 'river',\n",
       " 'wild',\n",
       " 'horse',\n",
       " 'via',\n",
       " '@change',\n",
       " '@calfreedommom',\n",
       " '@steph93065',\n",
       " 'mention',\n",
       " 'major',\n",
       " 'contributor',\n",
       " 'annihilation',\n",
       " 'israel',\n",
       " '@willienelson',\n",
       " 'need',\n",
       " 'help',\n",
       " '!',\n",
       " 'horses',\n",
       " 'die',\n",
       " '!',\n",
       " 'please',\n",
       " 'rt',\n",
       " 'amp',\n",
       " 'sign',\n",
       " 'petition',\n",
       " '!',\n",
       " 'take',\n",
       " 'stand',\n",
       " 'amp',\n",
       " 'voice',\n",
       " '!',\n",
       " '#gilbert23',\n",
       " 'httpstcoe',\n",
       " '8d',\n",
       " 'l1lncvu',\n",
       " 'stop',\n",
       " 'annihilation',\n",
       " 'salt',\n",
       " 'river',\n",
       " 'wild',\n",
       " 'horses',\n",
       " '!',\n",
       " 'via',\n",
       " '@change',\n",
       " 'world',\n",
       " 'annihilation',\n",
       " 'vs',\n",
       " 'self',\n",
       " 'transformation',\n",
       " 'aliens',\n",
       " 'attack',\n",
       " 'exterminate',\n",
       " 'humans',\n",
       " 'us',\n",
       " 'national',\n",
       " 'park',\n",
       " 'services',\n",
       " 'tonto',\n",
       " 'national',\n",
       " 'forest',\n",
       " 'stop',\n",
       " 'annihilation',\n",
       " 'salt',\n",
       " 'river',\n",
       " 'wild',\n",
       " 'horse',\n",
       " 'via',\n",
       " '@change',\n",
       " 'ohh',\n",
       " 'fukurodani',\n",
       " 'survive',\n",
       " 'apocalypse',\n",
       " 'bokuto',\n",
       " 'feels',\n",
       " 'horrible',\n",
       " 'poor',\n",
       " 'boy',\n",
       " 'ppor',\n",
       " 'child',\n",
       " 'another',\n",
       " 'hour',\n",
       " '!',\n",
       " 'august',\n",
       " '05',\n",
       " '2015',\n",
       " '0802pm',\n",
       " 'red',\n",
       " 'rover',\n",
       " 'zombie',\n",
       " 'apocalypse',\n",
       " '2014',\n",
       " '!',\n",
       " '#internetradio',\n",
       " '#collegeradiû_',\n",
       " 'know',\n",
       " 'question',\n",
       " 'interpretation',\n",
       " 'sign',\n",
       " 'apocalypse',\n",
       " 'called',\n",
       " 'httpstcomy',\n",
       " '8q1uwijn',\n",
       " 'begins',\n",
       " 'day',\n",
       " 'one',\n",
       " 'snow',\n",
       " 'apocalypse',\n",
       " 'dad',\n",
       " 'bought',\n",
       " 'dvd',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'science',\n",
       " 'doc',\n",
       " 'front',\n",
       " 'read',\n",
       " 'back',\n",
       " 'actually',\n",
       " 'impending',\n",
       " 'biblical',\n",
       " 'apocalypse',\n",
       " 'storm',\n",
       " 'cairo',\n",
       " 'latest',\n",
       " 'xmen',\n",
       " 'apocalypse',\n",
       " 'set',\n",
       " 'photo',\n",
       " 'httpstcofs',\n",
       " '012trudg',\n",
       " 'via',\n",
       " '@yahootv',\n",
       " 'latest',\n",
       " '@bryansinger',\n",
       " 'reveals',\n",
       " '#storm',\n",
       " 'queen',\n",
       " '#apocalypse',\n",
       " '@rupaul',\n",
       " '@alexshipppp',\n",
       " 'shadow',\n",
       " 'boxing',\n",
       " 'apocalypse',\n",
       " 'short',\n",
       " 'readingapocalypse',\n",
       " '211023',\n",
       " 'spirit',\n",
       " 'angel',\n",
       " 'took',\n",
       " 'top',\n",
       " 'enormous',\n",
       " 'high',\n",
       " 'mountain',\n",
       " '#pbban',\n",
       " 'temporary',\n",
       " '300',\n",
       " 'hyider_ghost',\n",
       " '2',\n",
       " '@armageddon',\n",
       " 'kill',\n",
       " 'flags',\n",
       " 'fast',\n",
       " 'xp',\n",
       " 'reason',\n",
       " 'vladimir',\n",
       " 'putin',\n",
       " 'issues',\n",
       " 'major',\n",
       " 'warning',\n",
       " 'late',\n",
       " 'escape',\n",
       " 'armageddon',\n",
       " '?',\n",
       " '@erker',\n",
       " '?',\n",
       " '?',\n",
       " 'eep',\n",
       " '!',\n",
       " 'thought',\n",
       " 'yesterday',\n",
       " 'saw',\n",
       " 'hella',\n",
       " 'scary',\n",
       " 'hail',\n",
       " '#armageddon',\n",
       " '?',\n",
       " 'paul',\n",
       " 'craig',\n",
       " 'roberts',\n",
       " 'ûò',\n",
       " 'vladimir',\n",
       " 'putin',\n",
       " 'issues',\n",
       " 'major',\n",
       " 'warning',\n",
       " 'late',\n",
       " 'escape',\n",
       " '#brics',\n",
       " '#roberts',\n",
       " '#russia',\n",
       " 'build',\n",
       " 'army',\n",
       " '100',\n",
       " 'dogs',\n",
       " 'leader',\n",
       " 'lion',\n",
       " 'dogs',\n",
       " 'fight',\n",
       " 'like',\n",
       " 'lion',\n",
       " 'one',\n",
       " 'direction',\n",
       " 'pick',\n",
       " 'fan',\n",
       " 'army',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_doc_1 = processor_1.corpus_doc\n",
    "corpus_word_1 = processor_1.corpus_word\n",
    "\n",
    "corpus_doc_0 = processor_0.corpus_doc\n",
    "corpus_word_0 = processor_0.corpus_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_1.generate_bow(corpus_word_1)\n",
    "bow_1 = processor_1.bow\n",
    "bow_fd_1 = processor_1.bow_fd\n",
    "\n",
    "processor_0.generate_bow(corpus_word_0)\n",
    "bow_0 = processor_0.bow\n",
    "bow_fd_0 = processor_0.bow_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_doc_1, corpus_word_1, bow_1, bow_fd_1 = load_corpus_bow('1')\n",
    "corpus_doc_0, corpus_word_0, bow_0, bow_fd_0 = load_corpus_bow('0')\n",
    "corpus_word_sw, bow_sw, bow_fd_sw = load_corpus_bow('sw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(processor_1.remove_stop_words)\n",
    "df['tokens'] = df['tokens'].apply(processor_0.remove_stop_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword                                               text  target  \\\n",
       "25  ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26  ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27  ablaze                 crying out for more! set me ablaze       0   \n",
       "28  ablaze  on plus side look at the sky last night it was...       0   \n",
       "29  ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "\n",
       "                                               tokens  \n",
       "25           [always, try, bring, heavy, #metal, #rt]  \n",
       "26  [#africanbaze, breaking, newsnigeria, flag, se...  \n",
       "27                           [crying, !, set, ablaze]  \n",
       "28       [plus, side, look, sky, last, night, ablaze]  \n",
       "29  [@phdsquares, #mufc, built, much, hype, around...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>birmingham wholesale market is ablaze bbc news...</td>\n",
       "      <td>[birmingham, wholesale, market, is, ablaze, bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "      <td>[@sunkxssedharry, will, you, wear, shorts, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#previouslyondoyintv toke makinwaûªs marriage ...</td>\n",
       "      <td>[#previouslyondoyintv, toke, makinwaûªs, marri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>check these out    #nsfw</td>\n",
       "      <td>[check, these, out, #nsfw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>psa iûªm splitting my personalities?? techies ...</td>\n",
       "      <td>[psa, iûªm, splitting, my, personalities, ?, ?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword                                               text  \\\n",
       "15  ablaze  birmingham wholesale market is ablaze bbc news...   \n",
       "16  ablaze  @sunkxssedharry will you wear shorts for race ...   \n",
       "17  ablaze  #previouslyondoyintv toke makinwaûªs marriage ...   \n",
       "18  ablaze                           check these out    #nsfw   \n",
       "19  ablaze  psa iûªm splitting my personalities?? techies ...   \n",
       "\n",
       "                                               tokens  \n",
       "15  [birmingham, wholesale, market, is, ablaze, bb...  \n",
       "16  [@sunkxssedharry, will, you, wear, shorts, for...  \n",
       "17  [#previouslyondoyintv, toke, makinwaûªs, marri...  \n",
       "18                         [check, these, out, #nsfw]  \n",
       "19  [psa, iûªm, splitting, my, personalities, ?, ?...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE - Comment out once saved\n",
    "\n",
    "df_to_save = df\n",
    "filename = 'C2_Initial_Processing/train.parquet'\n",
    "\n",
    "file_path = os.path.join(sdo_parq, filename)\n",
    "df_to_save.to_parquet(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C2_Initial_Processing/train.parquet'\n",
    "path_to_parq_store = os.path.join(sdo_parq, filename)\n",
    "\n",
    "df_train = pd.read_parquet(path_to_parq_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C2_Initial_Processing/test.parquet'\n",
    "path_to_parq_store = os.path.join(sdo_parq, filename)\n",
    "\n",
    "df_test = pd.read_parquet(path_to_parq_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[three, days, work, pretty, much, wrecked, hah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cramer, igers, 3, words, wrecked, disneys, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target  \\\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27     ablaze                 crying out for more! set me ablaze       0   \n",
       "28     ablaze  on plus side look at the sky last night it was...       0   \n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "...       ...                                                ...     ...   \n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0   \n",
       "6063  wrecked  three days off from work and they have pretty ...       0   \n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0   \n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0   \n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0   \n",
       "\n",
       "                                                 tokens  \n",
       "25             [always, try, bring, heavy, #metal, #rt]  \n",
       "26    [#africanbaze, breaking, newsnigeria, flag, se...  \n",
       "27                             [crying, !, set, ablaze]  \n",
       "28         [plus, side, look, sky, last, night, ablaze]  \n",
       "29    [@phdsquares, #mufc, built, much, hype, around...  \n",
       "...                                                 ...  \n",
       "6062              [@jt_ruff23, @cameronhacker, wrecked]  \n",
       "6063  [three, days, work, pretty, much, wrecked, hah...  \n",
       "6064  [#fx, #forex, #trading, cramer, igers, 3, word...  \n",
       "6065  [@engineshed, great, atmosphere, british, lion...  \n",
       "6066  [cramer, igers, 3, words, wrecked, disneys, st...  \n",
       "\n",
       "[6042 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'] = df['text'].apply(contractions.fix)\n",
    "# df_test['text'] = df_test['text'].apply(contractions.fix)\n",
    "\n",
    "# tokenizer = TweetTokenizer()\n",
    "# df['tokens'] = df['text'].apply(tokenizer.tokenize)\n",
    "# df_test['tokens'] = df_test['text'].apply(tokenizer.tokenize)\n",
    "\n",
    "# # Load corpus\n",
    "\n",
    "# processor_1 = CorpusBowCreator.create_corpus(df, 1, 'tokens')\n",
    "# processor_0 = CorpusBowCreator.create_corpus(df, 0, 'tokens')\n",
    "# df['tokens'] = df['tokens'].apply(processor_1.remove_stop_words)\n",
    "# df['tokens'] = df['tokens'].apply(processor_0.remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modularization.corpus_creation import CorpusBowCreatorSingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_creation_pipeline(df):\n",
    "    df['text'] = df['text'].apply(contractions.fix)\n",
    "\n",
    "    tokenizer = TweetTokenizer()\n",
    "    df['tokens'] = df['text'].apply(tokenizer.tokenize)\n",
    "\n",
    "    # Load corpus\n",
    "\n",
    "    corpus_creator = CorpusBowCreatorSingle.create_corpus(df, 'tokens')\n",
    "    df['tokens'] = df['tokens'].apply(corpus_creator.remove_stop_words)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# df_train = corpus_creation_pipeline(df_train)\n",
    "# df_test = corpus_creation_pipeline(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
