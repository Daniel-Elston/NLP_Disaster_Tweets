{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('axes', grid=True)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'C:/Users/delst/OneDrive/Desktop/Code/Workspace/NLP_Disaster_Tweets'\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from A_Root_Dir.Configurations.setup_env import setup_environment\n",
    "config = setup_environment(root_dir)\n",
    "\n",
    "# File Paths\n",
    "sdo_pkl = config.sdo_pkl\n",
    "sdo_parq = config.sdo_parq\n",
    "\n",
    "glove_input_dir = config.GloVe_input_dir\n",
    "glove_output_dir = config.GloVe_output_dir\n",
    "\n",
    "# Class Imports\n",
    "# from Modularization.corpus_bow import TextProcessor\n",
    "from Modularization.corpus_creation import load_corpus_bow\n",
    "\n",
    "fig_size = config.fig_size_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'E1_Feature_Extraction/train.parquet'\n",
    "path_to_parq_store = os.path.join(sdo_parq, filename)\n",
    "\n",
    "df_train = pd.read_parquet(path_to_parq_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "      <td>[#metal, #rt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "      <td>[#africanbaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "      <td>[#mufc]</td>\n",
       "      <td>[@phdsquares]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword                                               text  target  \\\n",
       "25  ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26  ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27  ablaze                 crying out for more! set me ablaze       0   \n",
       "28  ablaze  on plus side look at the sky last night it was...       0   \n",
       "29  ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "\n",
       "                                               tokens        hashtags  \\\n",
       "25           [always, try, bring, heavy, #metal, #rt]   [#metal, #rt]   \n",
       "26  [#africanbaze, breaking, newsnigeria, flag, se...  [#africanbaze]   \n",
       "27                           [crying, !, set, ablaze]              []   \n",
       "28       [plus, side, look, sky, last, night, ablaze]              []   \n",
       "29  [@phdsquares, #mufc, built, much, hype, around...         [#mufc]   \n",
       "\n",
       "         mentions questions exclamations  \n",
       "25             []        []           []  \n",
       "26             []        []           []  \n",
       "27             []        []          [!]  \n",
       "28             []        []           []  \n",
       "29  [@phdsquares]        []           []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_doc_1, corpus_word_1, bow_1, bow_fd_1 = load_corpus_bow('1')\n",
    "corpus_doc_0, corpus_word_0, bow_0, bow_fd_0 = load_corpus_bow('0')\n",
    "corpus_word_sw, bow_sw, bow_fd_sw = load_corpus_bow('sw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "      <td>[#metal, #rt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "      <td>[#africanbaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "      <td>[#mufc]</td>\n",
       "      <td>[@phdsquares]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[three, days, work, pretty, much, wrecked, hah...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "      <td>[#fx, #forex, #trading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cramer, igers, 3, words, wrecked, disneys, st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target  \\\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27     ablaze                 crying out for more! set me ablaze       0   \n",
       "28     ablaze  on plus side look at the sky last night it was...       0   \n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "...       ...                                                ...     ...   \n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0   \n",
       "6063  wrecked  three days off from work and they have pretty ...       0   \n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0   \n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0   \n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0   \n",
       "\n",
       "                                                 tokens  \\\n",
       "25             [always, try, bring, heavy, #metal, #rt]   \n",
       "26    [#africanbaze, breaking, newsnigeria, flag, se...   \n",
       "27                             [crying, !, set, ablaze]   \n",
       "28         [plus, side, look, sky, last, night, ablaze]   \n",
       "29    [@phdsquares, #mufc, built, much, hype, around...   \n",
       "...                                                 ...   \n",
       "6062              [@jt_ruff23, @cameronhacker, wrecked]   \n",
       "6063  [three, days, work, pretty, much, wrecked, hah...   \n",
       "6064  [#fx, #forex, #trading, cramer, igers, 3, word...   \n",
       "6065  [@engineshed, great, atmosphere, british, lion...   \n",
       "6066  [cramer, igers, 3, words, wrecked, disneys, st...   \n",
       "\n",
       "                     hashtags                      mentions questions  \\\n",
       "25              [#metal, #rt]                            []        []   \n",
       "26             [#africanbaze]                            []        []   \n",
       "27                         []                            []        []   \n",
       "28                         []                            []        []   \n",
       "29                    [#mufc]                 [@phdsquares]        []   \n",
       "...                       ...                           ...       ...   \n",
       "6062                       []  [@jt_ruff23, @cameronhacker]        []   \n",
       "6063                       []                            []        []   \n",
       "6064  [#fx, #forex, #trading]                            []        []   \n",
       "6065                       []                 [@engineshed]        []   \n",
       "6066                       []                            []        []   \n",
       "\n",
       "     exclamations  \n",
       "25             []  \n",
       "26             []  \n",
       "27            [!]  \n",
       "28             []  \n",
       "29             []  \n",
       "...           ...  \n",
       "6062           []  \n",
       "6063           []  \n",
       "6064           []  \n",
       "6065           []  \n",
       "6066           []  \n",
       "\n",
       "[6042 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lematisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "      <th>tokens_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "      <td>[#metal, #rt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "      <td>[#africanbaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[!]</td>\n",
       "      <td>[cry, !, set, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "      <td>[#mufc]</td>\n",
       "      <td>[@phdsquares]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[three, days, work, pretty, much, wrecked, hah...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[three, day, work, pretty, much, wrecked, haha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "      <td>[#fx, #forex, #trading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cramer, igers, 3, words, wrecked, disneys, st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cramer, igers, 3, word, wrecked, disney, stoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target  \\\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27     ablaze                 crying out for more! set me ablaze       0   \n",
       "28     ablaze  on plus side look at the sky last night it was...       0   \n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "...       ...                                                ...     ...   \n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0   \n",
       "6063  wrecked  three days off from work and they have pretty ...       0   \n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0   \n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0   \n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0   \n",
       "\n",
       "                                                 tokens  \\\n",
       "25             [always, try, bring, heavy, #metal, #rt]   \n",
       "26    [#africanbaze, breaking, newsnigeria, flag, se...   \n",
       "27                             [crying, !, set, ablaze]   \n",
       "28         [plus, side, look, sky, last, night, ablaze]   \n",
       "29    [@phdsquares, #mufc, built, much, hype, around...   \n",
       "...                                                 ...   \n",
       "6062              [@jt_ruff23, @cameronhacker, wrecked]   \n",
       "6063  [three, days, work, pretty, much, wrecked, hah...   \n",
       "6064  [#fx, #forex, #trading, cramer, igers, 3, word...   \n",
       "6065  [@engineshed, great, atmosphere, british, lion...   \n",
       "6066  [cramer, igers, 3, words, wrecked, disneys, st...   \n",
       "\n",
       "                     hashtags                      mentions questions  \\\n",
       "25              [#metal, #rt]                            []        []   \n",
       "26             [#africanbaze]                            []        []   \n",
       "27                         []                            []        []   \n",
       "28                         []                            []        []   \n",
       "29                    [#mufc]                 [@phdsquares]        []   \n",
       "...                       ...                           ...       ...   \n",
       "6062                       []  [@jt_ruff23, @cameronhacker]        []   \n",
       "6063                       []                            []        []   \n",
       "6064  [#fx, #forex, #trading]                            []        []   \n",
       "6065                       []                 [@engineshed]        []   \n",
       "6066                       []                            []        []   \n",
       "\n",
       "     exclamations                                        tokens_lemm  \n",
       "25             []           [always, try, bring, heavy, #metal, #rt]  \n",
       "26             []  [#africanbaze, breaking, newsnigeria, flag, se...  \n",
       "27            [!]                              [cry, !, set, ablaze]  \n",
       "28             []       [plus, side, look, sky, last, night, ablaze]  \n",
       "29             []  [@phdsquares, #mufc, built, much, hype, around...  \n",
       "...           ...                                                ...  \n",
       "6062           []              [@jt_ruff23, @cameronhacker, wrecked]  \n",
       "6063           []  [three, day, work, pretty, much, wrecked, haha...  \n",
       "6064           []  [#fx, #forex, #trading, cramer, igers, 3, word...  \n",
       "6065           []  [@engineshed, great, atmosphere, british, lion...  \n",
       "6066           []  [cramer, igers, 3, word, wrecked, disney, stoc...  \n",
       "\n",
       "[6042 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_lemmatizer(tokens):\n",
    "    lemm_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return lemm_tokens\n",
    "df['tokens_lemm'] = df['tokens'].apply(apply_lemmatizer)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GloVe Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delst\\AppData\\Local\\Temp\\ipykernel_24348\\3876710139.py:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1193514, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_input_file = os.path.join(glove_input_dir, 'glove.twitter.27B.25d.txt')\n",
    "word2vec_output_file = os.path.join(glove_output_dir, 'glove.twitter.27B.25d.txt.word2vec')\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load these vectors into a new model\n",
    "embed_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate average word vectors\n",
    "# def average_word_vectors(words, embed_model, num_features):\n",
    "def average_word_vectors(corpus, embed_model, num_features):\n",
    "\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    for word in corpus:\n",
    "        if word in embed_model:\n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, embed_model[word])\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "    return feature_vector\n",
    "\n",
    "# Define function to apply average word vectors to each document (list of tokens)\n",
    "def averaged_word_vectorizer(corpus, embed_model, num_features):\n",
    "    vocabulary = set(embed_model.index_to_key)\n",
    "    features = [average_word_vectors(tokenized_sentence, embed_model, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to our tokenized texts\n",
    "glove_features_tokens = averaged_word_vectorizer(corpus=df['tokens'], embed_model=embed_model, num_features=25) # corpus=df['tokens_lemm']\n",
    "glove_features_keyword = averaged_word_vectorizer(corpus=df['keyword'], embed_model=embed_model, num_features=25) # corpus=df['tokens_lemm']\n",
    "\n",
    "# glove_features is a 2D numpy array where each row is the vector representation of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_to_glove_features(df, embed_model, num_features):\n",
    "    df['tokens'] = df['text'].apply(tokenize)\n",
    "    glove_features = averaged_word_vectorizer(corpus=df['tokens'], embed_model=embed_model, num_features=num_features)\n",
    "    return glove_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the function to our tokenized texts\n",
    "# train_features = transform_data_to_glove_features(df, embed_model, 25)\n",
    "# test_features = transform_data_to_glove_features(test_df, embed_model, 25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_features_tokens_file_path = os.path.join(sdo_pkl, 'glove_features_tokens.pkl')\n",
    "glove_features_keyword_file_path = os.path.join(sdo_pkl, 'glove_features_keyword.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glove_features_tokens_file_path, 'wb') as file:\n",
    "    pickle.dump(glove_features_tokens, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glove_features_keyword_file_path, 'wb') as file:\n",
    "    pickle.dump(glove_features_keyword, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.448208  ,  0.6966934 , -0.62950339, ...,  0.41236001,\n",
       "         0.295904  , -0.29517521],\n",
       "       [-0.28123199, -0.14992025,  0.41934039, ...,  0.33308421,\n",
       "        -0.39357399, -0.1966228 ],\n",
       "       [-0.56035998, -0.30126308,  0.53712749, ...,  0.3417015 ,\n",
       "         0.28107351,  0.19530224],\n",
       "       ...,\n",
       "       [-0.44565713,  0.23500086, -0.14528557, ..., -0.01756999,\n",
       "        -0.83696286, -0.48966571],\n",
       "       [-0.77007711,  0.19694625,  0.10133375, ..., -0.1089725 ,\n",
       "        -0.74576937, -0.00999312],\n",
       "       [-0.38757999,  0.11865657,  0.220263  , ..., -0.06108142,\n",
       "        -0.57167999, -0.59350286]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(glove_features_tokens_file_path, 'rb') as file:\n",
    "    glove_features_tokens = pickle.load(file)\n",
    "glove_features_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53803501, 0.21774233, 0.05429499, ..., 0.41333501, 0.10137667,\n",
       "        0.20029733],\n",
       "       [0.53803501, 0.21774233, 0.05429499, ..., 0.41333501, 0.10137667,\n",
       "        0.20029733],\n",
       "       [0.53803501, 0.21774233, 0.05429499, ..., 0.41333501, 0.10137667,\n",
       "        0.20029733],\n",
       "       ...,\n",
       "       [0.79055715, 0.21167286, 0.06580042, ..., 0.35233899, 0.51870144,\n",
       "        0.22752613],\n",
       "       [0.79055715, 0.21167286, 0.06580042, ..., 0.35233899, 0.51870144,\n",
       "        0.22752613],\n",
       "       [0.79055715, 0.21167286, 0.06580042, ..., 0.35233899, 0.51870144,\n",
       "        0.22752613]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(glove_features_keyword_file_path, 'rb') as file:\n",
    "    glove_features_keyword = pickle.load(file)\n",
    "glove_features_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "      <th>tokens_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "      <td>[#metal, #rt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "      <td>[#africanbaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[!]</td>\n",
       "      <td>[cry, !, set, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "      <td>[#mufc]</td>\n",
       "      <td>[@phdsquares]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[three, days, work, pretty, much, wrecked, hah...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[three, day, work, pretty, much, wrecked, haha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "      <td>[#fx, #forex, #trading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cramer, igers, 3, words, wrecked, disneys, st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cramer, igers, 3, word, wrecked, disney, stoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target  \\\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27     ablaze                 crying out for more! set me ablaze       0   \n",
       "28     ablaze  on plus side look at the sky last night it was...       0   \n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "...       ...                                                ...     ...   \n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0   \n",
       "6063  wrecked  three days off from work and they have pretty ...       0   \n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0   \n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0   \n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0   \n",
       "\n",
       "                                                 tokens  \\\n",
       "25             [always, try, bring, heavy, #metal, #rt]   \n",
       "26    [#africanbaze, breaking, newsnigeria, flag, se...   \n",
       "27                             [crying, !, set, ablaze]   \n",
       "28         [plus, side, look, sky, last, night, ablaze]   \n",
       "29    [@phdsquares, #mufc, built, much, hype, around...   \n",
       "...                                                 ...   \n",
       "6062              [@jt_ruff23, @cameronhacker, wrecked]   \n",
       "6063  [three, days, work, pretty, much, wrecked, hah...   \n",
       "6064  [#fx, #forex, #trading, cramer, igers, 3, word...   \n",
       "6065  [@engineshed, great, atmosphere, british, lion...   \n",
       "6066  [cramer, igers, 3, words, wrecked, disneys, st...   \n",
       "\n",
       "                     hashtags                      mentions questions  \\\n",
       "25              [#metal, #rt]                            []        []   \n",
       "26             [#africanbaze]                            []        []   \n",
       "27                         []                            []        []   \n",
       "28                         []                            []        []   \n",
       "29                    [#mufc]                 [@phdsquares]        []   \n",
       "...                       ...                           ...       ...   \n",
       "6062                       []  [@jt_ruff23, @cameronhacker]        []   \n",
       "6063                       []                            []        []   \n",
       "6064  [#fx, #forex, #trading]                            []        []   \n",
       "6065                       []                 [@engineshed]        []   \n",
       "6066                       []                            []        []   \n",
       "\n",
       "     exclamations                                        tokens_lemm  \n",
       "25             []           [always, try, bring, heavy, #metal, #rt]  \n",
       "26             []  [#africanbaze, breaking, newsnigeria, flag, se...  \n",
       "27            [!]                              [cry, !, set, ablaze]  \n",
       "28             []       [plus, side, look, sky, last, night, ablaze]  \n",
       "29             []  [@phdsquares, #mufc, built, much, hype, around...  \n",
       "...           ...                                                ...  \n",
       "6062           []              [@jt_ruff23, @cameronhacker, wrecked]  \n",
       "6063           []  [three, day, work, pretty, much, wrecked, haha...  \n",
       "6064           []  [#fx, #forex, #trading, cramer, igers, 3, word...  \n",
       "6065           []  [@engineshed, great, atmosphere, british, lion...  \n",
       "6066           []  [cramer, igers, 3, word, wrecked, disney, stoc...  \n",
       "\n",
       "[6042 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE - Comment out once saved\n",
    "\n",
    "df_to_save = df\n",
    "filename = 'F1_Preprocessing/train.parquet'\n",
    "\n",
    "file_path = os.path.join(sdo_parq, filename)\n",
    "df_to_save.to_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "      <th>tokens_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "      <td>[#metal, #rt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "      <td>[#africanbaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[!]</td>\n",
       "      <td>[cry, !, set, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "      <td>[#mufc]</td>\n",
       "      <td>[@phdsquares]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[three, days, work, pretty, much, wrecked, hah...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[three, day, work, pretty, much, wrecked, haha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "      <td>[#fx, #forex, #trading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cramer, igers, 3, words, wrecked, disneys, st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cramer, igers, 3, word, wrecked, disney, stoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target  \\\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27     ablaze                 crying out for more! set me ablaze       0   \n",
       "28     ablaze  on plus side look at the sky last night it was...       0   \n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "...       ...                                                ...     ...   \n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0   \n",
       "6063  wrecked  three days off from work and they have pretty ...       0   \n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0   \n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0   \n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0   \n",
       "\n",
       "                                                 tokens  \\\n",
       "25             [always, try, bring, heavy, #metal, #rt]   \n",
       "26    [#africanbaze, breaking, newsnigeria, flag, se...   \n",
       "27                             [crying, !, set, ablaze]   \n",
       "28         [plus, side, look, sky, last, night, ablaze]   \n",
       "29    [@phdsquares, #mufc, built, much, hype, around...   \n",
       "...                                                 ...   \n",
       "6062              [@jt_ruff23, @cameronhacker, wrecked]   \n",
       "6063  [three, days, work, pretty, much, wrecked, hah...   \n",
       "6064  [#fx, #forex, #trading, cramer, igers, 3, word...   \n",
       "6065  [@engineshed, great, atmosphere, british, lion...   \n",
       "6066  [cramer, igers, 3, words, wrecked, disneys, st...   \n",
       "\n",
       "                     hashtags                      mentions questions  \\\n",
       "25              [#metal, #rt]                            []        []   \n",
       "26             [#africanbaze]                            []        []   \n",
       "27                         []                            []        []   \n",
       "28                         []                            []        []   \n",
       "29                    [#mufc]                 [@phdsquares]        []   \n",
       "...                       ...                           ...       ...   \n",
       "6062                       []  [@jt_ruff23, @cameronhacker]        []   \n",
       "6063                       []                            []        []   \n",
       "6064  [#fx, #forex, #trading]                            []        []   \n",
       "6065                       []                 [@engineshed]        []   \n",
       "6066                       []                            []        []   \n",
       "\n",
       "     exclamations                                        tokens_lemm  \n",
       "25             []           [always, try, bring, heavy, #metal, #rt]  \n",
       "26             []  [#africanbaze, breaking, newsnigeria, flag, se...  \n",
       "27            [!]                              [cry, !, set, ablaze]  \n",
       "28             []       [plus, side, look, sky, last, night, ablaze]  \n",
       "29             []  [@phdsquares, #mufc, built, much, hype, around...  \n",
       "...           ...                                                ...  \n",
       "6062           []              [@jt_ruff23, @cameronhacker, wrecked]  \n",
       "6063           []  [three, day, work, pretty, much, wrecked, haha...  \n",
       "6064           []  [#fx, #forex, #trading, cramer, igers, 3, word...  \n",
       "6065           []  [@engineshed, great, atmosphere, british, lion...  \n",
       "6066           []  [cramer, igers, 3, word, wrecked, disney, stoc...  \n",
       "\n",
       "[6042 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'F1_Preprocessing/train.parquet'\n",
    "path_to_parq_store = os.path.join(sdo_parq, filename)\n",
    "\n",
    "df_train = pd.read_parquet(path_to_parq_store)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modularization.preprocessing import Preprocessor\n",
    "from Modularization.preprocessing import Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delst\\AppData\\Local\\Temp\\ipykernel_24348\\160995163.py:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    }
   ],
   "source": [
    "glove_input_file = os.path.join(glove_input_dir, 'glove.twitter.27B.25d.txt')\n",
    "word2vec_output_file = os.path.join(glove_output_dir, 'glove.twitter.27B.25d.txt.word2vec')\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "embed_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(df):\n",
    "    preprocessor = Preprocessor(df, 'tokens')    \n",
    "    lemmatize_tokens = preprocessor.apply_lemmatizer()\n",
    "    \n",
    "    embedder = Embeddings(embed_model, 25)\n",
    "    embed_tokens = embedder.averaged_word_vectorizer(df['tokens'])\n",
    "    embed_keyword = embedder.averaged_word_vectorizer(df['keyword'])\n",
    "    \n",
    "    \n",
    "    return embed_tokens, embed_keyword\n",
    "\n",
    "\n",
    "# preprocessing_pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>questions</th>\n",
       "      <th>exclamations</th>\n",
       "      <th>tokens_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>we always try to bring the heavy #metal #rt</td>\n",
       "      <td>0</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "      <td>[#metal, #rt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[always, try, bring, heavy, #metal, #rt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#africanbaze breaking newsnigeria flag set abl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "      <td>[#africanbaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#africanbaze, breaking, newsnigeria, flag, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>crying out for more! set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>[crying, !, set, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[!]</td>\n",
       "      <td>[cry, !, set, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>on plus side look at the sky last night it was...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[plus, side, look, sky, last, night, ablaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@phdsquares #mufc they have built so much hype...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "      <td>[#mufc]</td>\n",
       "      <td>[@phdsquares]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@phdsquares, #mufc, built, much, hype, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@jt_ruff23 @cameronhacker and i wrecked you both</td>\n",
       "      <td>0</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jt_ruff23, @cameronhacker, wrecked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>three days off from work and they have pretty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[three, days, work, pretty, much, wrecked, hah...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[three, day, work, pretty, much, wrecked, haha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#fx #forex #trading cramer igers 3 words that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "      <td>[#fx, #forex, #trading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#fx, #forex, #trading, cramer, igers, 3, word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>@engineshed great atmosphere at the british li...</td>\n",
       "      <td>0</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@engineshed, great, atmosphere, british, lion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>cramer igers 3 words that wrecked disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[cramer, igers, 3, words, wrecked, disneys, st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cramer, igers, 3, word, wrecked, disney, stoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6042 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target  \\\n",
       "25     ablaze        we always try to bring the heavy #metal #rt       0   \n",
       "26     ablaze  #africanbaze breaking newsnigeria flag set abl...       1   \n",
       "27     ablaze                 crying out for more! set me ablaze       0   \n",
       "28     ablaze  on plus side look at the sky last night it was...       0   \n",
       "29     ablaze  @phdsquares #mufc they have built so much hype...       0   \n",
       "...       ...                                                ...     ...   \n",
       "6062  wrecked   @jt_ruff23 @cameronhacker and i wrecked you both       0   \n",
       "6063  wrecked  three days off from work and they have pretty ...       0   \n",
       "6064  wrecked  #fx #forex #trading cramer igers 3 words that ...       0   \n",
       "6065  wrecked  @engineshed great atmosphere at the british li...       0   \n",
       "6066  wrecked  cramer igers 3 words that wrecked disneys stoc...       0   \n",
       "\n",
       "                                                 tokens  \\\n",
       "25             [always, try, bring, heavy, #metal, #rt]   \n",
       "26    [#africanbaze, breaking, newsnigeria, flag, se...   \n",
       "27                             [crying, !, set, ablaze]   \n",
       "28         [plus, side, look, sky, last, night, ablaze]   \n",
       "29    [@phdsquares, #mufc, built, much, hype, around...   \n",
       "...                                                 ...   \n",
       "6062              [@jt_ruff23, @cameronhacker, wrecked]   \n",
       "6063  [three, days, work, pretty, much, wrecked, hah...   \n",
       "6064  [#fx, #forex, #trading, cramer, igers, 3, word...   \n",
       "6065  [@engineshed, great, atmosphere, british, lion...   \n",
       "6066  [cramer, igers, 3, words, wrecked, disneys, st...   \n",
       "\n",
       "                     hashtags                      mentions questions  \\\n",
       "25              [#metal, #rt]                            []        []   \n",
       "26             [#africanbaze]                            []        []   \n",
       "27                         []                            []        []   \n",
       "28                         []                            []        []   \n",
       "29                    [#mufc]                 [@phdsquares]        []   \n",
       "...                       ...                           ...       ...   \n",
       "6062                       []  [@jt_ruff23, @cameronhacker]        []   \n",
       "6063                       []                            []        []   \n",
       "6064  [#fx, #forex, #trading]                            []        []   \n",
       "6065                       []                 [@engineshed]        []   \n",
       "6066                       []                            []        []   \n",
       "\n",
       "     exclamations                                        tokens_lemm  \n",
       "25             []           [always, try, bring, heavy, #metal, #rt]  \n",
       "26             []  [#africanbaze, breaking, newsnigeria, flag, se...  \n",
       "27            [!]                              [cry, !, set, ablaze]  \n",
       "28             []       [plus, side, look, sky, last, night, ablaze]  \n",
       "29             []  [@phdsquares, #mufc, built, much, hype, around...  \n",
       "...           ...                                                ...  \n",
       "6062           []              [@jt_ruff23, @cameronhacker, wrecked]  \n",
       "6063           []  [three, day, work, pretty, much, wrecked, haha...  \n",
       "6064           []  [#fx, #forex, #trading, cramer, igers, 3, word...  \n",
       "6065           []  [@engineshed, great, atmosphere, british, lion...  \n",
       "6066           []  [cramer, igers, 3, word, wrecked, disney, stoc...  \n",
       "\n",
       "[6042 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
